\begin{frame}{Linear Transformations}
\begin{itemize}
    \item A mapping $T:\mathbb{R}^m \rightarrow \mathbb{R}^n$ is called \textbf{linear} if it satisfies
\begin{align}
    T(\alpha u + \beta v ) = \alpha T(u) + \beta T(v),\; \text{ for all } u, v\in \mathbb{R}^m, \; \alpha, \beta\in \mathbb{R}
\end{align}
\item Consider an $m\times n$ matrix $A$. It defines a linear transformation from $\mathbb{R}^m$ to $\mathbb{R}^n$ since
            \begin{align}
                A(\lambda x + \beta y) = A(\lambda x ) + A(\beta y ) = \lambda A x + \beta A y
            \end{align}
\end{itemize}
\end{frame}

\begin{frame}
    \begin{itemize}
      \item Another example: given $a\in \mathbb{R}^n$, the inner product $T(u)=\langle a, u\rangle$ for all $u\in \mathbb{R}^n$ is linear. Indeed, $T(\lambda u ) = \langle a, \lambda u \rangle = \lambda \langle a, u\rangle = \lambda T(u)$ and $T(u + v) = \langle a, u+v \rangle = \langle a, u\rangle+ \langle a, v\rangle = T(u) + T(v)$.
    \end{itemize}
\end{frame}

\begin{frame}{Exercise}
    \begin{itemize}
       \item Determine which of the following functions $T: \mathbb{R}^2 \rightarrow \mathbb{R}^2$ represent linear transformations:
\begin{enumerate}
    \item $T(x_1, x_2)=(1+x_1, x_2)$
    \item $T(x_1, x_2)=(x_2, x_1)$
    \item $T(x_1, x_2)=(x_1-x_2, 0)$
    \item $T(x_1, x_2)=(\sin x_1, x_2)$
    \item $T(x_1, x_2)=(x_1^2, x_2)$
\end{enumerate}
\item Given a linear transformation $T: \mathbb{R}^m\rightarrow \mathbb{R}^n$, prove that $T(\mathbf{0})=\mathbf{0}$. Does the property $T(\mathbf{1})=\mathbf{1}$ hold for the vector of ones?
    \end{itemize}
\end{frame}

\begin{frame}{Matrix Representation of Linear Transformations}
\begin{itemize}
    \item A linear transformation $T:\mathbb{R}^m \rightarrow \mathbb{R}^n$ can be represented by an $n\times m$ matrix $A$ such that for any vector $x\in \mathbb{R}^m$:
    \begin{align*}
        T(x) = Ax
    \end{align*}
    \item The matrix $A$ is constructed from the images of the standard basis vectors:
    \begin{align*}
        A = \begin{bmatrix}
            T(e_1) & T(e_2) & \cdots & T(e_m)
        \end{bmatrix}
    \end{align*}    
    where $e_i$ are the standard basis vectors in $\mathbb{R}^m$.
\end{itemize}
\end{frame}

\begin{frame}
    \begin{itemize}
     \item The columns of $A$ are the transformed basis vectors, i.e., $A = [T(e_1), T(e_2), \ldots, T(e_m)]$.
     \item For example, if  $T(e_1) = \begin{bmatrix} 1 \\ 0 \end{bmatrix}$ and $T(e_2) = \begin{bmatrix} 0 \\ 1 \end{bmatrix}$, then the matrix representation is:
     \begin{align*}
         A = \begin{bmatrix}
             1 & 0 \\
             0 & 1
         \end{bmatrix}
     \end{align*}
     \item This matrix $A$ represents the identity transformation in $\mathbb{R}^2$.
     \item The linear transformation can be visualized as a mapping of vectors in $\mathbb{R}^m$ to $\mathbb{R}^n$ through the matrix multiplication $Ax$.
    \end{itemize}
\end{frame}
\begin{frame}
    \begin{itemize}
        \item Example: For a linear transformation $T:\mathbb{R}^2 \rightarrow \mathbb{R}^2$ defined by $T(x_1, x_2) = (2x_1 + x_2, -x_1 + 3x_2)$, the matrix representation is:
        \begin{align*}
            A = \begin{bmatrix}
                T(e_1) & T(e_2) \\
                \downarrow & \downarrow \\
                2 & 1 \\
                -1 & 3
            \end{bmatrix}
        \end{align*}  
      where $T(e_1) = \begin{bmatrix} 2 \\ -1 \end{bmatrix}$ and $T(e_2) = \begin{bmatrix} 1 \\ 3 \end{bmatrix}$.
        \item The matrix $A$ can be used to compute the transformation of any vector $x = \begin{bmatrix} x_1 \\ x_2 \end{bmatrix}$ in $\mathbb{R}^2$ as:
    \end{itemize}
\end{frame}

\begin{frame}
    \begin{align*}
            T(x) = A x = \begin{bmatrix}
                2 & 1 \\
                -1 & 3
            \end{bmatrix} \begin{bmatrix}
                x_1 \\
                x_2
            \end{bmatrix}
    \end{align*}
    \begin{itemize}
                \item This results in a new vector in $\mathbb{R}^2$, which is the image of $x$ under the transformation $T$.
        \item The matrix representation allows for efficient computation of linear transformations, especially in higher dimensions.
    \end{itemize}
\end{frame}

\begin{frame}
\textbf{Exercices:}
\begin{itemize}
    \item Prove that the matrix representation of a linear transformation is unique.
    \item Show that if $T$ is a linear transformation, then $T(\mathbf{0}) = \mathbf{0}$.
    \item Given a linear transformation $T:\mathbb{R}^3 \rightarrow \mathbb{R}^2$ defined by $T(x_1, x_2, x_3) = (x_1 + 2x_2, 3x_3)$, find its matrix representation.
    \item For the linear transformation $T:\mathbb{R}^2 \rightarrow \mathbb{R}^2$ defined by $T(x_1, x_2) = (x_1 - x_2, 2x_1 + x_2)$, compute the image of the vector $x = (1, 2)$.
    \item If $T:\mathbb{R}^2 \rightarrow \mathbb{R}^2$ is defined by $T(x_1, x_2) = (3x_1 + x_2, -x_1 + 4x_2)$, find the matrix representation and compute $T(e_1)$ and $T(e_2)$, where $e_1 = (1, 0)$ and $e_2 = (0, 1)$.
\end{itemize}
\end{frame}

\begin{frame}{Image, Kernel, and Rank}
    Let $T:\mathbb{R}^m \rightarrow \mathbb{R}^n$ be a linear transformation. The following concepts are essential in understanding the properties of $T$:
    \begin{itemize}
        \item The \textbf{image} (or \textbf{range}) of $T$ is the set of all vectors that can be obtained as outputs, i.e.  
        \begin{align*}
            \text{Im}(T) = \{T(x)\in \mathbb{R}^n : x \in \mathbb{R}^m\}
        \end{align*}
        \item The \textbf{kernel} (or \textbf{null space}) of $T$ consists of all input vectors that are mapped to the zero vector, i.e. 
        \begin{align*}
             \text{Ker}(T) = \{x \in \mathbb{R}^m : T(x) = \mathbf{0}\}
        \end{align*}
    \end{itemize}
\end{frame}
\begin{frame}
    \begin{itemize}
    
        \item The \textbf{rank} of a linear transformation equals the dimension of its image, written as $\text{rank}(T)$.
        \item In other words, the rank is the number of linearly independent vectors in the image of $T$.
        \item The \textbf{nullity} of a linear transformation equals the dimension of its kernel, written as $\text{nullity}(T)$.  
    \end{itemize}
\end{frame}

\begin{frame}
    \textbf{Example:} Consider the linear transformation $T:\mathbb{R}^3 \rightarrow \mathbb{R}^2$ defined by:
    \begin{align*}
        T(x_1, x_2, x_3) = (x_1 + 2x_2, 3x_3)
    \end{align*}
    \begin{itemize}
        \item The image of $T$ is the set of all vectors in $\mathbb{R}^2$ that can be expressed as $(x_1 + 2x_2, 3x_3)$ for some $x_1, x_2, x_3 \in \mathbb{R}$.
        \item That is, the image consists of all vectors of the form $(a, b)$ where $a$ can take any value in $\mathbb{R}$ and $b$ can take any value in $\mathbb{R}$, leading to $\text{Im}(T) = \mathbb{R}^2$.
    \end{itemize}   
\end{frame}

\begin{frame}
    \begin{itemize}
        \item The kernel of $T$ consists of all vectors $(x_1, x_2, x_3)$ such that $T(x_1, x_2, x_3) = (0, 0)$, which leads to the equations $x_1 + 2x_2 = 0$ and $3x_3 = 0$.
        \item This implies that $x_3$ must be zero, and $x_1$ can be expressed in terms of $x_2$ as $x_1 = -2x_2$. Thus, the kernel can be described by the equation $x_1 + 2x_2 = 0$ and $x_3 = 0$, which is a line in $\mathbb{R}^3$.
        \item That is, $\text{Ker}(T) =  \{ ( x_1, x_2, x_3 ) \in \mathbb{R}^3 : x_1 = -2x_2, x_3 = 0\} $.
        \item  Or, the kernel can be expressed as:
        \begin{align*}
            \text{Ker}(T) = \left \{\begin{bmatrix} -2t\\ t\\ 0 \end{bmatrix} \in \mathbb{R}^3: t \in \mathbb{R} \right \} = \text{span}\left(\begin{bmatrix} -2\\ 1\\ 0 \end{bmatrix}\right)
        \end{align*}        
    \end{itemize}
\end{frame}
\begin{frame}
    \begin{itemize}
        \item The nullity of $T$ is the dimension of the kernel, which is 1, as it is spanned by one vector only.
        \item The rank of $T$ is the dimension of the image, which in this case is 2, since the image spans a plane in $\mathbb{R}^2$.
    \end{itemize}
\end{frame}


\begin{frame}
    \begin{block}{\textbf{Rank-Nullity Theorem}}
        For a linear transformation $T:\mathbb{R}^m \rightarrow \mathbb{R}^n$, the following relationship holds:
        \begin{align*}
            \text{rank}(T) + \text{nullity}(T) = m
        \end{align*}
        where $\text{rank}(T)$ is the dimension of the image of $T$ and $\text{nullity}(T)$ is the dimension of the kernel of $T$.
    \end{block}
     \textbf{Note:} This theorem connects the dimensions of the image and kernel of a linear transformation to the dimension of the domain.
\end{frame}

\begin{frame}
    \textbf{Example:} For the linear transformation $T:\mathbb{R}^3 \rightarrow \mathbb{R}^2$ defined by $T(x_1, x_2, x_3) = (x_1 + 2x_2, 3x_3)$:
    \begin{itemize}
        \item The rank of $T$ is 2 (dimension of the image $\mathbb{R}^2$).
        \item The nullity of $T$ is 1 (dimension of the kernel, which is a line in $\mathbb{R}^3$).
        \item Thus, by the rank-nullity theorem:
        \begin{align*}
            \text{rank}(T) + \text{nullity}(T) = 2 + 1 = 3
        \end{align*}
        which matches the dimension of the domain $\mathbb{R}^3$.
    \end{itemize}
\end{frame}

\begin{frame}
    \textbf{Exercise:} Let $T:\mathbb{R}^m \rightarrow \mathbb{R}^n$ be a linear transformation.
    \begin{itemize}
        \item Prove that $Ker(T)$ is a subspace of $\mathbb{R}^m$.
        \item Show that $Im(T)$  is a subspace of  $\mathbb{R}^n$.
    \end{itemize} 
    \textbf{Exercice:} 
    \begin{itemize}
        \item Prove the rank-nullity theorem for a linear transformation $T:\mathbb{R}^m \rightarrow \mathbb{R}^n$.
        \item Given a linear transformation $T:\mathbb{R}^3 \rightarrow \mathbb{R}^2$ defined by $T(x_1, x_2, x_3) = (x_1 + 2x_2, 3x_3)$, find the image and kernel of $T$.
        \item Determine the rank and nullity of the transformation $T$.
        \item Verify that the rank-nullity theorem holds for this transformation.
    \end{itemize}
  
\end{frame}
\begin{frame}
    \textbf{Exercise:} For the linear transformation $T:\mathbb{R}^3 \rightarrow \mathbb{R}^2$ defined by $T(x_1, x_2, x_3) = (x_1 + 2x_2, 3x_3)$:
    \begin{itemize}
        \item Find the image and kernel of $T$.
        \item Determine the rank and nullity of $T$.
        \item Verify that the rank-nullity theorem holds, i.e., $\text{rank}(T) + \text{nullity}(T) = m$, where $m$ is the dimension of the domain $\mathbb{R}^3$.
    \end{itemize}
\end{frame}



