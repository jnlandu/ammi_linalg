\begin{frame}{Eigendecomposition/Diagonalization}
    \begin{itemize}
        \item Consider a matrix $A$ possessing $n$ eigenvalues $\lambda_1, \ldots, \lambda_n$ and $n$ linearly independent eigenvectors $x_1, \ldots, x_n$. We can construct:
        \begin{itemize}
            \item Diagonal matrix: $D=\text{diag}(\lambda_1, \ldots, \lambda_n)$
            \item Matrix of eigenvectors: $P=[x_1 \; x_2 \; \cdots \; x_n]$
        \end{itemize}
        This allows us to represent $A$ as:
         \begin{align}
         A=P D P^{-1} =  P \begin{bmatrix}
        \lambda_1 & 0 & \cdots & 0 \\
        0 & \lambda_2 & \cdots & 0 \\
        \vdots & \vdots & \ddots & \vdots \\
        0 & 0 & \cdots & \lambda_n
        \end{bmatrix} P^{-1}
         \end{align}
         \item A matrix that allows such a decomposition is termed "diagonalizable". \textbf{A matrix is diagonalizable if and only if it can be expressed as $A = PDP^{-1}$.}
     \end{itemize}
    \end{frame}
    \begin{frame}{Example}
    \begin{itemize}
         \item \textbf{All symmetric matrices are diagonalizable.} The spectral theorem guarantees the existence of a matrix $P$ such that:
        \begin{align}
            A= PDP^{-1} \label{eqbon2,2}
        \end{align}
        \item Consider the matrix $A$:
        \[
        A = \begin{bmatrix}
        3 & 1 \\
        1 & 3
        \end{bmatrix}
        \]
        \item We aim to find the eigendecomposition $A = P DP^{-1}$, where $P$ has eigenvectors as columns and $D$ is the diagonal matrix of corresponding eigenvalues.
    \end{itemize}
    \end{frame}


    \begin{frame}{}
    \begin{itemize}
    \item  \textbf{Step 1: Find the Eigenvalues}. Solve \( \det(A - \lambda I) = 0 \):
    \begin{align*}
    p_A(\lambda) = \det(A - \lambda I) =\det\begin{bmatrix}
    3 - \lambda & 1 \\
    1 & 3 - \lambda
    \end{bmatrix} & = (3 - \lambda)^2 - 1 \\
    &  = \lambda^2 - 6\lambda + 8=(\lambda - 4)(\lambda - 2)
    \end{align*}
    \item The eigenvalues are: \( \sigma(A) = \{\lambda_1 = 4, \lambda_2 = 2 \}\).
     \item \textbf{Step 2: Find the Eigenvectors}

    For \( \lambda_1 = 4 \):

    Solve \( (A - 4I)\begin{bmatrix} x \\ y \end{bmatrix}  = 0  \Longleftrightarrow \begin{bmatrix} -1 & 1 \\ 1 & -1 \end{bmatrix} \begin{bmatrix} x \\ y \end{bmatrix} = 0 \). This yields:
    \[
    -x + y = 0 \implies y = x. \text{ Thus: } \; v_1 =\begin{bmatrix} 1 \\ 1 \end{bmatrix} 
    \]
    \end{itemize}
    \end{frame}

    \begin{frame}{}
    \begin{itemize}
    \item 
    For \( \lambda_2 = 2 \):

    Solve \( (A - 2I )\begin{bmatrix} x \\ y \end{bmatrix}  = 0 \Longleftrightarrow\begin{bmatrix} 1 & 1 \\ 1 & 1 \end{bmatrix} \begin{bmatrix} x \\ y \end{bmatrix} = 0 \). This gives:
    \[
    x + y = 0 \implies y = -x. \text{ Thus: } \; v_2=\begin{bmatrix} 1 \\ -1 \end{bmatrix}
    \]
    \item  \textbf{Step 3: Form $D$ and $P$:}
        \begin{align*}
           P = \begin{bmatrix}
        1 & 1 \\
        1 & -1
        \end{bmatrix}, \quad D = \begin{bmatrix}
        4 & 0 \\
        0 & 2
        \end{bmatrix} 
        \end{align*}
    \end{itemize}
    \end{frame}


    \begin{frame}{Conditions for Diagonalization}
    \begin{itemize}
    \item  Not all matrices are symmetric. We must therefore establish conditions for a matrix to be diagonalizable. Let $A$ be an $n\times n$ matrix.
      \item \textbf{Condition 1:} \( A \) is diagonalizable if there exists a basis of \( \mathbb{R}^n \) composed of eigenvectors of \( A \), i.e., \textbf{\( A \) possesses \( n \) linearly independent eigenvectors.}

        \item \textbf{Condition 2:} If  $A$ \textbf{has \( n \) distinct eigenvalues}, then it is diagonalizable (since eigenvectors corresponding to distinct eigenvalues are linearly independent).
        \item \textbf{Condition 3: }  $A$ is diagonalizable if   \textbf{$A$ satisfies  $GM=AM$.}
    \end{itemize}
    \end{frame}
    \begin{frame}{Exercises: Diagonalizability }
    \begin{itemize}
        \item Determine which of the following matrices are diagonalizable over \( \mathbb{R} \). Provide justification for your answer.
    \end{itemize}

    \vspace{0.5em}
    \begin{align*}
        \text{a)}\;\; A &= \begin{bmatrix}
            1 & 0 \\
            0 & 0
        \end{bmatrix} 
        \qquad 
        \text{b)}\;\; B = \begin{bmatrix}
            2 & 1 \\
            0 & 2
        \end{bmatrix} 
        \qquad 
        \text{c)}\;\; C = \begin{bmatrix}
            0 & 1 \\
            -1 & 0
        \end{bmatrix} \\[1.5em]
        \text{d)}\;\; D &= \begin{bmatrix}
            5 & 4 & 2 \\
            0 & 1 & -1 \\
            0 & 0 & 3
        \end{bmatrix}
        \qquad 
        \text{e)}\;\; E = \begin{bmatrix}
            4 & 1 & 1 \\
            1 & 4 & 1 \\
            1 & 1 & 4
        \end{bmatrix} 
        \qquad 
        \text{f)}\;\; F = \begin{bmatrix}
            0 & 1 & 0 \\
            0 & 0 & 1 \\
            0 & 0 & 0
        \end{bmatrix}
    \end{align*}
    \end{frame}




